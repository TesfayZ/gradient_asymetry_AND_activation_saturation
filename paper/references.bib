@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{lowe2017multi,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Wu, Yi I and Tamar, Aviv and Harb, Jean and Pieter Abbeel, OpenAI and Mordatch, Igor},
  booktitle={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle={Advances in neural information processing systems},
  volume={12},
  year={2000}
}

@article{hochreiter1998vanishing,
  title={The vanishing gradient problem during learning recurrent neural nets and problem solutions},
  author={Hochreiter, Sepp},
  journal={International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  volume={6},
  number={02},
  pages={107--116},
  year={1998},
  publisher={World Scientific}
}

@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{eimer2023hyperparameters,
  title={Hyperparameters in reinforcement learning and how to tune them},
  author={Eimer, Theresa and Lindauer, Marius and Raileanu, Roberta},
  booktitle={International Conference on Machine Learning},
  pages={9104--9149},
  year={2023},
  organization={PMLR}
}

@article{zahavy2020self,
  title={A self-tuning actor-critic algorithm},
  author={Zahavy, Tom and Xu, Zhongwen and Veeriah, Vivek and Hessel, Matteo and Oh, Junhyuk and van Hasselt, Hado P and Silver, David and Singh, Satinder},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20913--20924},
  year={2020}
}

@article{henderson2018deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  journal={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{andrychowicz2020matters,
  title={What matters in on-policy reinforcement learning? a large-scale empirical study},
  author={Andrychowicz, Marcin and Raichuk, Anton and Sta{\'n}czyk, Piotr and others},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{yu2020gradient,
  title={Gradient surgery for multi-task learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5824--5836},
  year={2020}
}

@article{ma2020dsac,
  title={DSAC: Distributional soft actor critic for risk-sensitive reinforcement learning},
  author={Ma, Xiaoteng and Zhang, Qiyuan and Xia, Li and Zhou, Zhengyuan and Yang, Jun and Zhao, Qianchuan},
  journal={arXiv preprint arXiv:2004.14547},
  year={2020}
}

@article{wang2020multiagent,
  title={Multi-agent deep reinforcement learning for task offloading in mobile edge computing},
  author={Wang, Jin and Hu, Jia and Min, Geyong and Zhan, Wenhan and Zomaya, Albert Y and Georgalas, Nektarios},
  journal={IEEE Transactions on Mobile Computing},
  year={2020}
}

@article{ccm_madrl,
  title={Client-Master Multiagent Deep Reinforcement Learning for Task Offloading in Mobile Edge Computing},
  author={Gebrekidan, Tesfay Zemuy and Stein, Sebastian and Norman, Timothy J.},
  journal={ACM Transactions on Autonomous and Adaptive Systems},
  volume={19},
  number={3},
  pages={1--26},
  year={2024},
  publisher={ACM},
  doi={10.1145/3768579},
  url={https://dl.acm.org/doi/abs/10.1145/3768579},
  note={Also available at arXiv:2402.11653}
}

@article{ccm_madrl_arxiv,
  title={Client-Master Multiagent Deep Reinforcement Learning for Task Offloading in Mobile Edge Computing},
  author={Gebrekidan, Tesfay Zemuy and Stein, Sebastian and Norman, Timothy J.},
  journal={arXiv preprint arXiv:2402.11653},
  year={2024},
  url={https://arxiv.org/abs/2402.11653}
}

@inproceedings{pinto2017asymmetric,
  title={Asymmetric actor critic for image-based robot learning},
  author={Pinto, Lerrel and Andrychowicz, Marcin and Welinder, Peter and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={Robotics: Science and Systems},
  year={2017}
}

@article{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@article{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  journal={International conference on machine learning},
  pages={1587--1596},
  year={2018},
  organization={PMLR}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  journal={International conference on machine learning},
  pages={1928--1937},
  year={2016},
  organization={PMLR}
}

@phdthesis{gebrekidan2024thesis,
  title={Deep Reinforcement Learning for Online Combinatorial Resource Allocation with Arbitrary State and Action Spaces},
  author={Gebrekidan, Tesfay Zemuy},
  year={2024},
  school={University of Southampton},
  url={https://eprints.soton.ac.uk/491435/}
}

@article{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
  journal={Advances in neural information processing systems},
  volume={12},
  year={2000}
}

@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={International conference on machine learning},
  pages={387--395},
  year={2014},
  organization={PMLR}
}

@article{bengio1994learning,
  title={Learning long-term dependencies with gradient descent is difficult},
  author={Bengio, Yoshua and Simard, Patrice and Frasconi, Paolo},
  journal={IEEE transactions on neural networks},
  volume={5},
  number={2},
  pages={157--166},
  year={1994},
  publisher={IEEE}
}

@inproceedings{pascanu2013difficulty,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={1310--1318},
  year={2013},
  organization={PMLR}
}

@inproceedings{nair2010rectified,
  title={Rectified linear units improve restricted boltzmann machines},
  author={Nair, Vinod and Hinton, Geoffrey E},
  booktitle={International conference on machine learning},
  pages={807--814},
  year={2010}
}

@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015}
}

@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={PMLR}
}

@article{islam2017reproducibility,
  title={Reproducibility of benchmarked deep reinforcement learning tasks for continuous control},
  author={Islam, Riashat and Henderson, Peter and Gomrokchi, Maziar and Precup, Doina},
  journal={arXiv preprint arXiv:1708.04133},
  year={2017}
}

@inproceedings{wu2021gradient,
  title={Gradient normalization for generative adversarial networks},
  author={Wu, Yi-Lun and Shuai, Hong-Han and Tam, Zhi-Rui and Chiu, Hong-Yu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6373--6382},
  year={2021}
}

@inproceedings{cobbe2021phasic,
  title={Phasic policy gradient},
  author={Cobbe, Karl and Hilton, Jacob and Klimov, Oleg and Schulman, John},
  booktitle={International Conference on Machine Learning},
  pages={2020--2027},
  year={2021},
  organization={PMLR}
}

@inproceedings{ilyas2020closer,
  title={A closer look at deep policy gradients},
  author={Ilyas, Andrew and Engstrom, Logan and Santurkar, Shibani and Tsipras, Dimitris and Janoos, Firdaus and Rudolph, Larry and Madry, Aleksander},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{chen2019optimized,
  title={Optimized computation offloading performance in virtual edge computing systems via deep reinforcement learning},
  author={Chen, Xianfu and Zhang, Honggang and Wu, Celimuge and Mao, Shiwen and Ji, Yusheng and Bennis, Mehdi},
  journal={IEEE Internet of Things Journal},
  volume={6},
  number={3},
  pages={4005--4018},
  year={2019},
  publisher={IEEE}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT press}
}

@article{raffin2021smooth,
  title={Smooth exploration for robotic reinforcement learning},
  author={Raffin, Antonin and Kober, Jens and Stulp, Freek},
  journal={Conference on Robot Learning},
  pages={1634--1644},
  year={2021},
  organization={PMLR}
}

@misc{spinningup2018,
  author={Achiam, Joshua},
  title={{Spinning Up in Deep Reinforcement Learning}},
  year={2018},
  howpublished={\url{https://spinningup.openai.com/}}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{wang2016dueling,
  title={Dueling network architectures for deep reinforcement learning},
  author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Hasselt, Hado and Lanctot, Marc and Freitas, Nando},
  booktitle={International conference on machine learning},
  pages={1995--2003},
  year={2016},
  organization={PMLR}
}

@inproceedings{ota2020can,
  title={Can increasing input dimensionality improve deep reinforcement learning?},
  author={Ota, Kei and Oiki, Tomoaki and Jha, Devesh and Mariyama, Toshisada and Nikovski, Daniel},
  booktitle={International Conference on Machine Learning},
  pages={7424--7433},
  year={2020},
  organization={PMLR}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@inproceedings{chou2017improving,
  title={Improving stochastic policy gradients in continuous control with deep reinforcement learning using the beta distribution},
  author={Chou, Po-Wei and Maturana, Daniel and Scherer, Sebastian},
  booktitle={International conference on machine learning},
  pages={834--843},
  year={2017},
  organization={PMLR}
}
