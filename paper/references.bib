@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{lowe2017multi,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Wu, Yi I and Tamar, Aviv and Harb, Jean and Pieter Abbeel, OpenAI and Mordatch, Igor},
  booktitle={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle={Advances in neural information processing systems},
  volume={12},
  year={2000}
}

@article{hochreiter1998vanishing,
  title={The vanishing gradient problem during learning recurrent neural nets and problem solutions},
  author={Hochreiter, Sepp},
  journal={International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  volume={6},
  number={02},
  pages={107--116},
  year={1998},
  publisher={World Scientific}
}

@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{eimer2023hyperparameters,
  title={Hyperparameters in reinforcement learning and how to tune them},
  author={Eimer, Theresa and Lindauer, Marius and Raileanu, Roberta},
  booktitle={International Conference on Machine Learning},
  pages={9104--9149},
  year={2023},
  organization={PMLR}
}

@article{zahavy2020self,
  title={A self-tuning actor-critic algorithm},
  author={Zahavy, Tom and Xu, Zhongwen and Veeriah, Vivek and Hessel, Matteo and Oh, Junhyuk and van Hasselt, Hado P and Silver, David and Singh, Satinder},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20913--20924},
  year={2020}
}

@article{henderson2018deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  journal={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{andrychowicz2020matters,
  title={What matters in on-policy reinforcement learning? a large-scale empirical study},
  author={Andrychowicz, Marcin and Raichuk, Anton and Sta{\'n}czyk, Piotr and others},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{yu2020gradient,
  title={Gradient surgery for multi-task learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5824--5836},
  year={2020}
}

@article{ma2020dsac,
  title={DSAC: Distributional soft actor critic for risk-sensitive reinforcement learning},
  author={Ma, Xiaoteng and Xia, Li and Zhou, Zhengyuan and Yang, Jun and Zhao, Qianchuan},
  journal={arXiv preprint arXiv:2004.14547},
  year={2020}
}

@article{wang2020multiagent,
  title={Multi-agent deep reinforcement learning for task offloading in mobile edge computing},
  author={Wang, Jin and Hu, Jia and Min, Geyong and Zhan, Wenhan and Zomaya, Albert Y and Georgalas, Nektarios},
  journal={IEEE Transactions on Mobile Computing},
  year={2020}
}

@article{ccm_madrl,
  title={Client-Master Multiagent Deep Reinforcement Learning for Task Offloading in Mobile Edge Computing},
  author={Gebrekidan, Tesfay Zemuy and Shojafar, Mohammad and Pooranian, Zahra and Persico, Valerio and Pescap√©, Antonio},
  journal={ACM Transactions on Autonomous and Adaptive Systems},
  year={2024},
  doi={10.1145/3768579}
}

@inproceedings{pinto2017asymmetric,
  title={Asymmetric actor critic for image-based robot learning},
  author={Pinto, Lerrel and Andrychowicz, Marcin and Welinder, Peter and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={Robotics: Science and Systems},
  year={2017}
}

@article{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@article{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  journal={International conference on machine learning},
  pages={1587--1596},
  year={2018},
  organization={PMLR}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  journal={International conference on machine learning},
  pages={1928--1937},
  year={2016},
  organization={PMLR}
}
