{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Actor Experiment - Testing if Larger Architecture Prevents Saturation\n",
    "\n",
    "**Hypothesis:** Making the actor have the same hidden layer sizes as the critic (512 -> 128 instead of 64 -> 32) may help avoid tanh saturation.\n",
    "\n",
    "## Architecture Comparison\n",
    "\n",
    "| Network | Original | Large Actor (This Experiment) |\n",
    "|---------|----------|-------------------------------|\n",
    "| Actor   | 7->64->32->3 | 7->**512**->**128**->3 |\n",
    "| Critic  | 510->512->128->1 | 510->512->128->1 |\n",
    "\n",
    "## Learning Rate Order (High to Low)\n",
    "Experiments run from **HIGH to LOW** learning rates to prioritize early-stopping cases:\n",
    "- Actor LRs: `[0.1, 0.01, 0.001, 0.0001]`\n",
    "- Critic LRs: `[0.1, 0.01, 0.001, 0.0001]`\n",
    "- Total: **16 experiments**\n",
    "\n",
    "---\n",
    "\n",
    "## Features:\n",
    "- Auto-saves to Google Drive every 100 episodes\n",
    "- Auto-restores from Drive on session restart\n",
    "- Crash recovery built-in\n",
    "- Early stopping when all actors stop updating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"Google Drive mounted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Upload and Extract Experiment Files\n",
    "\n",
    "**Option A:** Upload `large_actor_experiment.zip` when prompted\n",
    "\n",
    "**Option B:** If you already uploaded to Drive, skip the upload prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Check if files already exist\n",
    "if os.path.exists('/content/large_actor_experiment/mec_env.py'):\n",
    "    print(\"Experiment files already present!\")\n",
    "else:\n",
    "    # Try to find zip in Drive first\n",
    "    drive_zip = '/content/drive/MyDrive/large_actor_experiment.zip'\n",
    "    \n",
    "    if os.path.exists(drive_zip):\n",
    "        print(f\"Found zip in Drive: {drive_zip}\")\n",
    "        zip_path = drive_zip\n",
    "    else:\n",
    "        # Upload zip file\n",
    "        print(\"Upload large_actor_experiment.zip:\")\n",
    "        from google.colab import files\n",
    "        uploaded = files.upload()\n",
    "        zip_path = list(uploaded.keys())[0]\n",
    "    \n",
    "    # Extract\n",
    "    print(f\"Extracting {zip_path}...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall('/content')\n",
    "    \n",
    "    print(\"\\nExtracted files:\")\n",
    "    for item in os.listdir('/content'):\n",
    "        if not item.startswith('.'):\n",
    "            print(f\"  {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Check GPU and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"\")\n",
    "    print(\"WARNING: No GPU detected!\")\n",
    "    print(\"Go to: Runtime -> Change runtime type -> GPU\")\n",
    "\n",
    "# Set working directory\n",
    "os.chdir('/content')\n",
    "print(f\"\\nWorking directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Verify Large Actor Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/content/large_actor_experiment')\n",
    "\n",
    "from Model import LargeActorNetwork, ActorNetwork, CriticNetwork\n",
    "import torch\n",
    "\n",
    "# Compare architectures\n",
    "small_actor = ActorNetwork(7, 3, torch.tanh)\n",
    "large_actor = LargeActorNetwork(7, 3, torch.tanh)\n",
    "critic = CriticNetwork(350, 150, 7, 3)  # 50 agents * 7 state, 50 agents * 3 action\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"ARCHITECTURE COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nSmall Actor (original): 7 -> 64 -> 32 -> 3\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in small_actor.parameters()):,}\")\n",
    "print(f\"\\nLarge Actor (this experiment): 7 -> 512 -> 128 -> 3\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in large_actor.parameters()):,}\")\n",
    "print(f\"\\nCritic: 510 -> 512 -> 128 -> 1\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in critic.parameters()):,}\")\n",
    "print(f\"\\nLarge Actor / Critic ratio: {sum(p.numel() for p in large_actor.parameters()) / sum(p.numel() for p in critic.parameters()):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Run All 16 Experiments\n",
    "\n",
    "This will run all 16 experiments with **HIGH learning rates FIRST**:\n",
    "- Actor LRs: `[0.1, 0.01, 0.001, 0.0001]` (high to low)\n",
    "- Critic LRs: `[0.1, 0.01, 0.001, 0.0001]` (high to low)\n",
    "\n",
    "**Progress is auto-saved to Google Drive every 100 episodes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/content')\n",
    "sys.path.insert(0, '/content/large_actor_experiment')\n",
    "\n",
    "from run_large_actor_experiment import run_all_experiments\n",
    "\n",
    "# Run all experiments\n",
    "run_all_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Check Experiment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "results_dir = '/content/results/large_actor_experiment'\n",
    "status_file = os.path.join(results_dir, 'experiment_status.json')\n",
    "\n",
    "if os.path.exists(status_file):\n",
    "    with open(status_file) as f:\n",
    "        status = json.load(f)\n",
    "    print(\"Experiment Status:\")\n",
    "    print(f\"  Completed: {len(status['completed'])}/16\")\n",
    "    if status['in_progress']:\n",
    "        print(f\"  In progress: {status['in_progress']}\")\n",
    "    print(\"\\nCompleted experiments:\")\n",
    "    for exp in sorted(status['completed']):\n",
    "        print(f\"  - {exp}\")\n",
    "else:\n",
    "    print(\"No status file found yet.\")\n",
    "\n",
    "# Also check Drive backup\n",
    "drive_dir = '/content/drive/MyDrive/large_actor_results'\n",
    "if os.path.exists(drive_dir):\n",
    "    print(f\"\\nDrive backup exists: {drive_dir}\")\n",
    "    contents = os.listdir(drive_dir)\n",
    "    print(f\"  Contents: {contents[:5]}...\" if len(contents) > 5 else f\"  Contents: {contents}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: View Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "results_dir = '/content/results/large_actor_experiment'\n",
    "\n",
    "if os.path.exists(results_dir):\n",
    "    print(\"Large Actor Experiment Results Summary:\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"{'Actor LR':<12} {'Critic LR':<12} {'Stop Ep.':<12} {'Final Reward':<15}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    results = []\n",
    "    for exp_dir in sorted(os.listdir(results_dir)):\n",
    "        result_file = os.path.join(results_dir, exp_dir, 'results.json')\n",
    "        if os.path.exists(result_file):\n",
    "            with open(result_file) as f:\n",
    "                data = json.load(f)\n",
    "            results.append(data)\n",
    "    \n",
    "    # Sort by actor_lr (descending) then critic_lr (descending)\n",
    "    for data in sorted(results, key=lambda x: (-x['actor_lr'], -x['critic_lr'])):\n",
    "        print(f\"{data['actor_lr']:<12} {data['critic_lr']:<12} {data['stopping_episode']:<12} {data['final_reward']:<15.4f}\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"No results directory found yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Compare with Original Experiment (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def load_results(results_dir):\n",
    "    results = []\n",
    "    if os.path.exists(results_dir):\n",
    "        for exp_dir in os.listdir(results_dir):\n",
    "            result_file = os.path.join(results_dir, exp_dir, 'results.json')\n",
    "            if os.path.exists(result_file):\n",
    "                with open(result_file) as f:\n",
    "                    results.append(json.load(f))\n",
    "    return results\n",
    "\n",
    "large_results = load_results('/content/results/large_actor_experiment')\n",
    "original_results = load_results('/content/results/stopping_experiment')\n",
    "\n",
    "# Also try Drive backups\n",
    "if not original_results:\n",
    "    original_results = load_results('/content/drive/MyDrive/gradient_asymmetry_results')\n",
    "\n",
    "if original_results and large_results:\n",
    "    print(\"COMPARISON: Original (Small Actor) vs Large Actor\")\n",
    "    print(\"=\"*85)\n",
    "    print(f\"{'Actor LR':<10} {'Critic LR':<10} {'Original Stop':<15} {'Large Stop':<15} {'Difference':<15}\")\n",
    "    print(\"-\"*85)\n",
    "    \n",
    "    for orig in sorted(original_results, key=lambda x: (-x['actor_lr'], -x['critic_lr'])):\n",
    "        large = next((r for r in large_results \n",
    "                     if r['actor_lr'] == orig['actor_lr'] and r['critic_lr'] == orig['critic_lr']), None)\n",
    "        if large:\n",
    "            diff = large['stopping_episode'] - orig['stopping_episode']\n",
    "            diff_str = f\"+{diff}\" if diff > 0 else str(diff)\n",
    "            improved = \"IMPROVED\" if diff > 100 else \"\"\n",
    "            print(f\"{orig['actor_lr']:<10} {orig['critic_lr']:<10} {orig['stopping_episode']:<15} {large['stopping_episode']:<15} {diff_str:<10} {improved}\")\n",
    "    print(\"=\"*85)\n",
    "elif large_results:\n",
    "    print(\"Original experiment results not found for comparison.\")\n",
    "    print(\"Upload original results to '/content/results/stopping_experiment' to compare.\")\n",
    "else:\n",
    "    print(\"No large actor results found yet. Run the experiment first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Download Results (Optional)\n",
    "\n",
    "Results are auto-backed up to Drive, but you can also download a zip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "results_dir = '/content/results/large_actor_experiment'\n",
    "output_zip = '/content/large_actor_results.zip'\n",
    "\n",
    "if os.path.exists(results_dir):\n",
    "    shutil.make_archive('/content/large_actor_results', 'zip', results_dir)\n",
    "    print(f\"Created: {output_zip}\")\n",
    "    print(f\"Size: {os.path.getsize(output_zip) / 1024:.1f} KB\")\n",
    "    \n",
    "    # Download\n",
    "    from google.colab import files\n",
    "    files.download(output_zip)\n",
    "else:\n",
    "    print(\"No results directory found.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
