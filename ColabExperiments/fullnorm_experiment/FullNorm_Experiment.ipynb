{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Full Normalization Experiment - RunningNorm + Post-activation LayerNorm\n\n**Hypothesis:** The recommended RL normalization strategy combines:\n- **RunningNorm (input)**: Normalizes using running mean/std (like BatchNorm statistics)\n- **Post-activation LayerNorm**: After each hidden ReLU layer for gradient stability\n- **NO LayerNorm before tanh**: Avoids forcing saturation\n- **NO LayerNorm on critic output**: Preserves TD error signal\n\n## Why RunningNorm instead of LayerNorm for input?\n- LayerNorm normalizes across features within a single sample\n- RunningNorm tracks population statistics across samples (more stable for RL)\n- Better handles the non-stationary nature of RL data distributions\n\n## Architecture Comparison\n\n| Experiment | Actor Architecture | Critic Architecture |\n|------------|-------------------|---------------------|\n| Original | 7->64->ReLU->32->ReLU->tanh->3 | 510->512->ReLU->128->ReLU->1 |\n| LayerNorm | 7->64->ReLU->32->ReLU->**LN**->tanh->3 | (unchanged) |\n| **FullNorm** | **RunningNorm**->64->ReLU->**LN**->32->ReLU->**LN**->tanh->3 | **RunningNorm**->512->ReLU->**LN**->128->ReLU->**LN**->1 |\n\n## Key Insight\nIn RL, **magnitude matters as much as direction**. Post-activation LN preserves relative magnitudes while stabilizing gradients. Pre-tanh LN forces ~N(0,1) which pushes many values toward saturation.\n\n## Learning Rate Order (High to Low)\nExperiments run from **HIGH to LOW** learning rates to prioritize early-stopping cases:\n- Actor LRs: `[0.1, 0.01, 0.001, 0.0001]`\n- Critic LRs: `[0.1, 0.01, 0.001, 0.0001]`\n- Total: **16 experiments**"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"Google Drive mounted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 2: Setup - Choose Start Mode\n\nThe experiment script **automatically restores from Google Drive** when you run it. Choose how to proceed:\n\n- **Option 1: Continue** - Run experiments (auto-restores completed ones from Drive)\n- **Option 2: Start Fresh** - Clear ALL results (local + Drive) and start from scratch  \n- **Option 3: Import from Zip** - Import results from a downloaded zip file"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport zipfile\nimport shutil\nimport json\n\nEXPERIMENT_NAME = 'fullnorm_experiment'\nEXPERIMENT_ZIP = f'{EXPERIMENT_NAME}.zip'\nRESULTS_DIR = f'/content/results/{EXPERIMENT_NAME}'\nEXPERIMENT_DIR = f'/content/{EXPERIMENT_NAME}'\nDRIVE_BACKUP_DIR = '/content/drive/MyDrive/fullnorm_results'\n\n# ============================================================\n# STEP 1: Extract experiment files\n# ============================================================\nif not os.path.exists(f'{EXPERIMENT_DIR}/mec_env.py'):\n    drive_zip = f'/content/drive/MyDrive/{EXPERIMENT_ZIP}'\n    \n    if os.path.exists(drive_zip):\n        print(f\"Found experiment zip in Drive: {drive_zip}\")\n        zip_path = drive_zip\n    else:\n        print(f\"Upload {EXPERIMENT_ZIP}:\")\n        from google.colab import files\n        uploaded = files.upload()\n        zip_path = list(uploaded.keys())[0]\n    \n    print(f\"Extracting {zip_path}...\")\n    with zipfile.ZipFile(zip_path, 'r') as z:\n        z.extractall('/content')\n    print(\"Experiment files extracted!\")\nelse:\n    print(\"Experiment files already present!\")\n\n# ============================================================\n# STEP 2: Check existing progress\n# ============================================================\ndrive_status_file = os.path.join(DRIVE_BACKUP_DIR, 'experiment_status.json')\nif os.path.exists(drive_status_file):\n    with open(drive_status_file) as f:\n        drive_status = json.load(f)\n    drive_completed = len(drive_status.get('completed', []))\n    in_progress = drive_status.get('in_progress')\n    print(f\"\\n*** Found Drive backup: {drive_completed}/16 completed ***\")\n    if in_progress:\n        print(f\"    Last in progress: {in_progress} (will restart this one)\")\nelse:\n    drive_completed = 0\n    print(\"\\n*** No existing Drive backup found ***\")\n\n# ============================================================\n# CHOOSE START MODE\n# ============================================================\nprint(\"\\n\" + \"=\" * 60)\nprint(\"SELECT START MODE\")\nprint(\"=\" * 60)\nprint(\"1. Continue - Auto-restore from Drive and run remaining\")\nprint(\"2. Start Fresh - Clear ALL results and start from scratch\")\nprint(\"3. Import from Zip - Upload results zip to restore\")\nprint(\"=\" * 60)\n\nstart_mode = input(\"Enter choice (1/2/3): \").strip()\n\nif start_mode == '2':\n    print(\"\\n\" + \"=\" * 60)\n    print(\"STARTING FRESH - Clearing all results\")\n    print(\"=\" * 60)\n    if os.path.exists(RESULTS_DIR):\n        shutil.rmtree(RESULTS_DIR)\n        print(f\"Cleared: {RESULTS_DIR}\")\n    if os.path.exists(DRIVE_BACKUP_DIR):\n        shutil.rmtree(DRIVE_BACKUP_DIR)\n        print(f\"Cleared: {DRIVE_BACKUP_DIR}\")\n    print(\"Ready to run all 16 experiments from scratch!\")\n\nelif start_mode == '3':\n    print(\"\\n\" + \"=\" * 60)\n    print(\"IMPORT FROM ZIP\")\n    print(\"=\" * 60)\n    \n    print(\"Upload your results zip file:\")\n    from google.colab import files\n    uploaded = files.upload()\n    results_zip_path = list(uploaded.keys())[0]\n    \n    temp_dir = '/content/temp_import'\n    if os.path.exists(temp_dir):\n        shutil.rmtree(temp_dir)\n    os.makedirs(temp_dir)\n    \n    with zipfile.ZipFile(results_zip_path, 'r') as z:\n        z.extractall(temp_dir)\n    \n    actual_results = temp_dir\n    for root, dirs, files_list in os.walk(temp_dir):\n        if 'experiment_status.json' in files_list:\n            actual_results = root\n            break\n    \n    if os.path.exists(DRIVE_BACKUP_DIR):\n        shutil.rmtree(DRIVE_BACKUP_DIR)\n    shutil.copytree(actual_results, DRIVE_BACKUP_DIR)\n    \n    with open(os.path.join(DRIVE_BACKUP_DIR, 'experiment_status.json')) as f:\n        imported_status = json.load(f)\n    print(f\"Imported {len(imported_status.get('completed', []))} completed experiments to Drive\")\n    print(\"The experiment script will auto-restore these when you run it.\")\n    \n    shutil.rmtree(temp_dir)\n\nelse:\n    print(\"\\n\" + \"=\" * 60)\n    print(\"CONTINUE MODE\")\n    print(\"=\" * 60)\n    if drive_completed > 0:\n        print(f\"Will auto-restore {drive_completed} completed experiments from Drive\")\n    print(\"Ready to run!\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"SETUP COMPLETE - Run the next cell to start experiments\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Check GPU and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"\")\n",
    "    print(\"WARNING: No GPU detected!\")\n",
    "    print(\"Go to: Runtime -> Change runtime type -> GPU\")\n",
    "\n",
    "# Set working directory\n",
    "os.chdir('/content')\n",
    "print(f\"\\nWorking directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Verify FullNorm Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nsys.path.insert(0, '/content/fullnorm_experiment')\n\nfrom Model import FullNormActorNetwork, FullNormCriticNetwork, ActorNetwork, CriticNetwork, RunningNorm\nimport torch\n\n# Compare architectures\noriginal_actor = ActorNetwork(7, 3, torch.tanh)\nfullnorm_actor = FullNormActorNetwork(7, 3, torch.tanh)\noriginal_critic = CriticNetwork(350, 150, 7, 3)\nfullnorm_critic = FullNormCriticNetwork(350, 150, 7, 3)\n\nprint(\"=\" * 70)\nprint(\"ARCHITECTURE COMPARISON\")\nprint(\"=\" * 70)\nprint(f\"\\nOriginal Actor: 7 -> 64 -> ReLU -> 32 -> ReLU -> tanh -> 3\")\nprint(f\"  Parameters: {sum(p.numel() for p in original_actor.parameters()):,}\")\nprint(f\"\\nFullNorm Actor: RunningNorm -> 64 -> ReLU -> LN -> 32 -> ReLU -> LN -> tanh -> 3\")\nprint(f\"  Parameters: {sum(p.numel() for p in fullnorm_actor.parameters()):,}\")\nprint(f\"\\nOriginal Critic: 510 -> 512 -> ReLU -> 128 -> ReLU -> 1\")\nprint(f\"  Parameters: {sum(p.numel() for p in original_critic.parameters()):,}\")\nprint(f\"\\nFullNorm Critic: RunningNorm -> 512 -> ReLU -> LN -> 128 -> ReLU -> LN -> 1\")\nprint(f\"  Parameters: {sum(p.numel() for p in fullnorm_critic.parameters()):,}\")\n\n# Show the FullNorm modules\nprint(\"\\n\" + \"=\" * 70)\nprint(\"FullNorm Actor Modules:\")\nprint(\"=\" * 70)\nfor name, module in fullnorm_actor.named_modules():\n    if name:\n        print(f\"  {name}: {module}\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"FullNorm Critic Modules:\")\nprint(\"=\" * 70)\nfor name, module in fullnorm_critic.named_modules():\n    if name:\n        print(f\"  {name}: {module}\")\n\n# Show RunningNorm details\nprint(\"\\n\" + \"=\" * 70)\nprint(\"RunningNorm Details (Actor Input):\")\nprint(\"=\" * 70)\nprint(f\"  Features: {fullnorm_actor.input_norm.num_features}\")\nprint(f\"  Momentum: {fullnorm_actor.input_norm.momentum}\")\nprint(f\"  Initial running_mean: {fullnorm_actor.input_norm.running_mean}\")\nprint(f\"  Initial running_var: {fullnorm_actor.input_norm.running_var}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Run All 16 Experiments\n",
    "\n",
    "This will run all 16 experiments with **HIGH learning rates FIRST**:\n",
    "- Actor LRs: `[0.1, 0.01, 0.001, 0.0001]` (high to low)\n",
    "- Critic LRs: `[0.1, 0.01, 0.001, 0.0001]` (high to low)\n",
    "\n",
    "**Progress is auto-saved to Google Drive every 100 episodes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/content')\n",
    "sys.path.insert(0, '/content/fullnorm_experiment')\n",
    "\n",
    "from run_fullnorm_experiment import run_all_experiments\n",
    "\n",
    "# Run all experiments\n",
    "run_all_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Check Experiment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "results_dir = '/content/results/fullnorm_experiment'\n",
    "status_file = os.path.join(results_dir, 'experiment_status.json')\n",
    "\n",
    "if os.path.exists(status_file):\n",
    "    with open(status_file) as f:\n",
    "        status = json.load(f)\n",
    "    print(\"Experiment Status:\")\n",
    "    print(f\"  Completed: {len(status['completed'])}/16\")\n",
    "    if status['in_progress']:\n",
    "        print(f\"  In progress: {status['in_progress']}\")\n",
    "    print(\"\\nCompleted experiments:\")\n",
    "    for exp in sorted(status['completed']):\n",
    "        print(f\"  - {exp}\")\n",
    "else:\n",
    "    print(\"No status file found yet.\")\n",
    "\n",
    "# Also check Drive backup\n",
    "drive_dir = '/content/drive/MyDrive/fullnorm_results'\n",
    "if os.path.exists(drive_dir):\n",
    "    print(f\"\\nDrive backup exists: {drive_dir}\")\n",
    "    contents = os.listdir(drive_dir)\n",
    "    print(f\"  Contents: {contents[:5]}...\" if len(contents) > 5 else f\"  Contents: {contents}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: View Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "results_dir = '/content/results/fullnorm_experiment'\n",
    "\n",
    "if os.path.exists(results_dir):\n",
    "    print(\"FullNorm Experiment Results Summary:\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"{'Actor LR':<12} {'Critic LR':<12} {'Stop Ep.':<12} {'Final Reward':<15}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    results = []\n",
    "    for exp_dir in sorted(os.listdir(results_dir)):\n",
    "        result_file = os.path.join(results_dir, exp_dir, 'results.json')\n",
    "        if os.path.exists(result_file):\n",
    "            with open(result_file) as f:\n",
    "                data = json.load(f)\n",
    "            results.append(data)\n",
    "    \n",
    "    for data in sorted(results, key=lambda x: (-x['actor_lr'], -x['critic_lr'])):\n",
    "        print(f\"{data['actor_lr']:<12} {data['critic_lr']:<12} {data['stopping_episode']:<12} {data['final_reward']:<15.4f}\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"No results directory found yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Compare All Three Experiments (Original vs LayerNorm vs FullNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def load_results(results_dir):\n",
    "    results = []\n",
    "    if os.path.exists(results_dir):\n",
    "        for exp_dir in os.listdir(results_dir):\n",
    "            result_file = os.path.join(results_dir, exp_dir, 'results.json')\n",
    "            if os.path.exists(result_file):\n",
    "                with open(result_file) as f:\n",
    "                    results.append(json.load(f))\n",
    "    return results\n",
    "\n",
    "# Load all results\n",
    "fullnorm_results = load_results('/content/results/fullnorm_experiment')\n",
    "layernorm_results = load_results('/content/results/layernorm_experiment')\n",
    "original_results = load_results('/content/results/stopping_experiment')\n",
    "\n",
    "# Try Drive backups\n",
    "if not fullnorm_results:\n",
    "    fullnorm_results = load_results('/content/drive/MyDrive/fullnorm_results')\n",
    "if not layernorm_results:\n",
    "    layernorm_results = load_results('/content/drive/MyDrive/layernorm_results')\n",
    "if not original_results:\n",
    "    original_results = load_results('/content/drive/MyDrive/gradient_asymmetry_results')\n",
    "\n",
    "print(\"COMPARISON: Original vs LayerNorm vs FullNorm\")\n",
    "print(\"=\"*100)\n",
    "print(f\"{'Actor LR':<10} {'Critic LR':<10} {'Original':<12} {'LayerNorm':<12} {'FullNorm':<12} {'Best':<15}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "for actor_lr in [0.1, 0.01, 0.001, 0.0001]:\n",
    "    for critic_lr in [0.1, 0.01, 0.001, 0.0001]:\n",
    "        orig = next((r for r in original_results if r['actor_lr'] == actor_lr and r['critic_lr'] == critic_lr), None)\n",
    "        ln = next((r for r in layernorm_results if r['actor_lr'] == actor_lr and r['critic_lr'] == critic_lr), None)\n",
    "        fn = next((r for r in fullnorm_results if r['actor_lr'] == actor_lr and r['critic_lr'] == critic_lr), None)\n",
    "        \n",
    "        orig_ep = orig['stopping_episode'] if orig else '-'\n",
    "        ln_ep = ln['stopping_episode'] if ln else '-'\n",
    "        fn_ep = fn['stopping_episode'] if fn else '-'\n",
    "        \n",
    "        # Determine best (highest stopping episode = longest training)\n",
    "        values = []\n",
    "        if orig: values.append(('Original', orig['stopping_episode']))\n",
    "        if ln: values.append(('LayerNorm', ln['stopping_episode']))\n",
    "        if fn: values.append(('FullNorm', fn['stopping_episode']))\n",
    "        \n",
    "        best = max(values, key=lambda x: x[1])[0] if values else '-'\n",
    "        \n",
    "        print(f\"{actor_lr:<10} {critic_lr:<10} {str(orig_ep):<12} {str(ln_ep):<12} {str(fn_ep):<12} {best:<15}\")\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"\\nNote: Higher stopping episode = longer training before actor gradients vanish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Analyze Gradient Asymmetry Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def get_asymmetry_stats(results_dir):\n",
    "    stats = {}\n",
    "    if os.path.exists(results_dir):\n",
    "        for exp_dir in os.listdir(results_dir):\n",
    "            tracking_file = os.path.join(results_dir, exp_dir, 'tracking_data.json')\n",
    "            result_file = os.path.join(results_dir, exp_dir, 'results.json')\n",
    "            if os.path.exists(tracking_file) and os.path.exists(result_file):\n",
    "                with open(tracking_file) as f:\n",
    "                    tracking = json.load(f)\n",
    "                with open(result_file) as f:\n",
    "                    result = json.load(f)\n",
    "                \n",
    "                asym = tracking.get('asymmetry_history', [])\n",
    "                if asym:\n",
    "                    ratios = [a['ratio'] for a in asym if a['ratio'] != float('inf')]\n",
    "                    if ratios:\n",
    "                        key = (result['actor_lr'], result['critic_lr'])\n",
    "                        stats[key] = {\n",
    "                            'mean_ratio': np.mean(ratios),\n",
    "                            'final_ratio': ratios[-1] if ratios else 0,\n",
    "                            'stopping_episode': result['stopping_episode']\n",
    "                        }\n",
    "    return stats\n",
    "\n",
    "# Load asymmetry stats\n",
    "fullnorm_stats = get_asymmetry_stats('/content/results/fullnorm_experiment')\n",
    "if not fullnorm_stats:\n",
    "    fullnorm_stats = get_asymmetry_stats('/content/drive/MyDrive/fullnorm_results')\n",
    "\n",
    "layernorm_stats = get_asymmetry_stats('/content/results/layernorm_experiment')\n",
    "if not layernorm_stats:\n",
    "    layernorm_stats = get_asymmetry_stats('/content/drive/MyDrive/layernorm_results')\n",
    "\n",
    "if fullnorm_stats or layernorm_stats:\n",
    "    print(\"Gradient Asymmetry Analysis (Actor/Critic Gradient Ratio):\")\n",
    "    print(\"=\"*90)\n",
    "    print(f\"{'Actor LR':<10} {'Critic LR':<10} {'LayerNorm Ratio':<18} {'FullNorm Ratio':<18} {'Improvement':<15}\")\n",
    "    print(\"-\"*90)\n",
    "    \n",
    "    for actor_lr in [0.1, 0.01, 0.001, 0.0001]:\n",
    "        for critic_lr in [0.1, 0.01, 0.001, 0.0001]:\n",
    "            key = (actor_lr, critic_lr)\n",
    "            ln_ratio = layernorm_stats.get(key, {}).get('mean_ratio', '-')\n",
    "            fn_ratio = fullnorm_stats.get(key, {}).get('mean_ratio', '-')\n",
    "            \n",
    "            if isinstance(ln_ratio, float) and isinstance(fn_ratio, float):\n",
    "                # Closer to 1.0 is better (balanced gradients)\n",
    "                ln_dist = abs(1.0 - ln_ratio)\n",
    "                fn_dist = abs(1.0 - fn_ratio)\n",
    "                improvement = \"FullNorm\" if fn_dist < ln_dist else \"LayerNorm\"\n",
    "            else:\n",
    "                improvement = \"-\"\n",
    "            \n",
    "            ln_str = f\"{ln_ratio:.4f}\" if isinstance(ln_ratio, float) else str(ln_ratio)\n",
    "            fn_str = f\"{fn_ratio:.4f}\" if isinstance(fn_ratio, float) else str(fn_ratio)\n",
    "            \n",
    "            print(f\"{actor_lr:<10} {critic_lr:<10} {ln_str:<18} {fn_str:<18} {improvement:<15}\")\n",
    "    \n",
    "    print(\"=\"*90)\n",
    "    print(\"\\nNote: Ratio closer to 1.0 = more balanced actor/critic gradients\")\n",
    "else:\n",
    "    print(\"No asymmetry data found yet. Run experiments first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Analyze Pre-activation Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "results_dir = '/content/results/fullnorm_experiment'\n",
    "if not os.path.exists(results_dir):\n",
    "    results_dir = '/content/drive/MyDrive/fullnorm_results'\n",
    "\n",
    "if os.path.exists(results_dir):\n",
    "    print(\"Pre-activation Statistics (before tanh - should be moderate without forcing N(0,1)):\")\n",
    "    print(\"=\"*85)\n",
    "    print(f\"{'Actor LR':<10} {'Critic LR':<10} {'Min Preact':<15} {'Max Preact':<15} {'Saturation':<15}\")\n",
    "    print(\"-\"*85)\n",
    "    \n",
    "    for exp_dir in sorted(os.listdir(results_dir)):\n",
    "        tracking_file = os.path.join(results_dir, exp_dir, 'tracking_data.json')\n",
    "        result_file = os.path.join(results_dir, exp_dir, 'results.json')\n",
    "        if os.path.exists(tracking_file) and os.path.exists(result_file):\n",
    "            with open(tracking_file) as f:\n",
    "                tracking = json.load(f)\n",
    "            with open(result_file) as f:\n",
    "                result = json.load(f)\n",
    "            \n",
    "            act_hist = tracking.get('activation_history', [])\n",
    "            if act_hist:\n",
    "                last = act_hist[-1]\n",
    "                print(f\"{result['actor_lr']:<10} {result['critic_lr']:<10} {last['min_preact']:<15.2f} {last['max_preact']:<15.2f} {last['avg_actor_output_saturation']:<15.2%}\")\n",
    "    print(\"=\"*85)\n",
    "    print(\"\\nNote: FullNorm should keep pre-activations moderate without forcing exact N(0,1)\")\n",
    "    print(\"This allows the network to learn appropriate output scales naturally.\")\n",
    "else:\n",
    "    print(\"No results found yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "results_dir = '/content/results/fullnorm_experiment'\n",
    "output_zip = '/content/fullnorm_results.zip'\n",
    "\n",
    "if os.path.exists(results_dir):\n",
    "    shutil.make_archive('/content/fullnorm_results', 'zip', results_dir)\n",
    "    print(f\"Created: {output_zip}\")\n",
    "    print(f\"Size: {os.path.getsize(output_zip) / 1024:.1f} KB\")\n",
    "    \n",
    "    # Download\n",
    "    from google.colab import files\n",
    "    files.download(output_zip)\n",
    "else:\n",
    "    print(\"No results directory found.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}